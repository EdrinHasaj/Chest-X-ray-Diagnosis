{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelBinarizer class order: ['No Finding' 'Atelectasis' 'Cardiomegaly' 'Effusion' 'Infiltration'\n",
      " 'Mass' 'Nodule' 'Pneumonia' 'Pneumothorax' 'Consolidation' 'Edema'\n",
      " 'Emphysema' 'Fibrosis' 'Pleural_Thickening' 'Hernia']\n",
      "First few processed labels (raw): [['Cardiomegaly'], ['Cardiomegaly', 'Emphysema'], ['Cardiomegaly', 'Effusion'], ['No Finding'], ['Hernia']]\n",
      "First few processed labels (one-hot): [array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]), array([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])]\n"
     ]
    }
   ],
   "source": [
    "# Load CSV data\n",
    "df = pd.read_csv(\"/student/csc490_project/shared/labels.csv\")\n",
    "\n",
    "# Define the 15 classes (14 diseases plus \"No Finding\")\n",
    "CLASSES = [\n",
    "    \"No Finding\", \"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\", \n",
    "    \"Mass\", \"Nodule\", \"Pneumonia\", \"Pneumothorax\", \"Consolidation\", \n",
    "    \"Edema\", \"Emphysema\", \"Fibrosis\", \"Pleural_Thickening\", \"Hernia\"\n",
    "]\n",
    "\n",
    "# Process the \"Finding Labels\" column (split by '|' so that \"No Finding\" becomes [\"No Finding\"])\n",
    "def process_labels(label_str):\n",
    "    return label_str.split(\"|\")\n",
    "\n",
    "df[\"label_list\"] = df[\"Finding Labels\"].apply(process_labels)\n",
    "\n",
    "# Initialize MultiLabelBinarizer with the defined CLASSES\n",
    "mlb = MultiLabelBinarizer(classes=CLASSES)\n",
    "labels_array = mlb.fit_transform(df[\"label_list\"])\n",
    "\n",
    "# Save the one-hot encoded labels into a new column\n",
    "df[\"labels\"] = list(labels_array)\n",
    "\n",
    "# Print some samples to verify order\n",
    "print(\"MultiLabelBinarizer class order:\", mlb.classes_)\n",
    "print(\"First few processed labels (raw):\", df[\"label_list\"].head().tolist())\n",
    "print(\"First few processed labels (one-hot):\", df[\"labels\"].head().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose training transforms: apply augmentation, then convert to 3 channels and apply other augmentations.\n",
    "train_transforms_list = []\n",
    "train_transforms_list += [\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "]\n",
    "train_transform = transforms.Compose(train_transforms_list)\n",
    "\n",
    "# Validation transforms: deterministic preprocessing only\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: DataFrame with \"Image Index\" and \"labels\" columns.\n",
    "            root_dir: Directory where images are stored.\n",
    "            transform: Transformations to apply.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.df.iloc[idx][\"Image Index\"])\n",
    "        image = Image.open(img_name).convert(\"L\")  # load in grayscale\n",
    "        \n",
    "        # Get the one-hot label vector\n",
    "        labels = np.array(self.df.iloc[idx][\"labels\"], dtype=np.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.float)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model_name, train_df, val_df, epochs=7, batch_size=16):\n",
    "    # Adjust epochs for specific models\n",
    "    if model_name == 'convnext_large.fb_in22k':\n",
    "        epochs = 4\n",
    "\n",
    "    # Create model using timm\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=len(CLASSES))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_dataset = ChestXrayDataset(train_df, \n",
    "                                     root_dir=\"/student/csc490_project/shared/preprocessed_images/preprocessed_images\", \n",
    "                                     transform=train_transform)\n",
    "    val_dataset = ChestXrayDataset(val_df, \n",
    "                                   root_dir=\"/student/csc490_project/shared/preprocessed_images/preprocessed_images\", \n",
    "                                   transform=val_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        print(f\"Model: {model_name} | Epoch {epoch+1}/{epochs} | Training Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    \n",
    "    # Compute AUROC for each class\n",
    "    auroc_per_class = {}\n",
    "    for i, class_name in enumerate(CLASSES):\n",
    "        try:\n",
    "            auroc = roc_auc_score(all_labels[:, i], all_preds[:, i])\n",
    "        except ValueError:\n",
    "            auroc = float('nan')\n",
    "        auroc_per_class[class_name] = auroc\n",
    "    overall_auroc = np.nanmean(list(auroc_per_class.values()))\n",
    "    \n",
    "    return model, auroc_per_class, overall_auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'convnext_large.fb_in22k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 ---\n",
      "Train patient IDs (first 5): [27591 25556 10934  3797 14489]\n",
      "Val patient IDs (first 5): [12681 13125 29707 24851 12409]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867b4dc4d8fc4dfaaa946f1c7716c851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/919M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: convnext_large.fb_in22k | Epoch 1/4 | Training Loss: 0.1840\n",
      "Model: convnext_large.fb_in22k | Epoch 2/4 | Training Loss: 0.1709\n",
      "Model: convnext_large.fb_in22k | Epoch 3/4 | Training Loss: 0.1631\n",
      "Model: convnext_large.fb_in22k | Epoch 4/4 | Training Loss: 0.1521\n",
      "Per-class AUROC for this fold: {'No Finding': 0.7802405601319709, 'Atelectasis': 0.8181094588156417, 'Cardiomegaly': 0.9174144498957955, 'Effusion': 0.8805445079887244, 'Infiltration': 0.7190620513257876, 'Mass': 0.8370202736970409, 'Nodule': 0.7706921710384741, 'Pneumonia': 0.7436877713935887, 'Pneumothorax': 0.8790048253909694, 'Consolidation': 0.8112203224455712, 'Edema': 0.8838916336391769, 'Emphysema': 0.9204368794206614, 'Fibrosis': 0.8210068084256763, 'Pleural_Thickening': 0.7922324245974283, 'Hernia': 0.9450556995539985}\n",
      "Overall AUROC for this fold: 0.834641322517367\n",
      "Model for Fold 1 saved to /student/csc490_project/shared/cv_no_overlap/convnext_large.fb_in22k_fold1_model.pth\n",
      "\n",
      "--- Fold 2 ---\n",
      "Train patient IDs (first 5): [12681 13125 29707 24851 12409]\n",
      "Val patient IDs (first 5): [27591 25556 10934  3797 14489]\n",
      "Model: convnext_large.fb_in22k | Epoch 1/4 | Training Loss: 0.1845\n",
      "Model: convnext_large.fb_in22k | Epoch 2/4 | Training Loss: 0.1715\n",
      "Model: convnext_large.fb_in22k | Epoch 3/4 | Training Loss: 0.1637\n",
      "Model: convnext_large.fb_in22k | Epoch 4/4 | Training Loss: 0.1535\n",
      "Per-class AUROC for this fold: {'No Finding': 0.7784952058484107, 'Atelectasis': 0.8117306168452869, 'Cardiomegaly': 0.9038770984070255, 'Effusion': 0.8758743926902981, 'Infiltration': 0.723415243722338, 'Mass': 0.8632212743822523, 'Nodule': 0.7788893747397609, 'Pneumonia': 0.7689473023494844, 'Pneumothorax': 0.8674096341374, 'Consolidation': 0.7984158750171182, 'Edema': 0.9042360202200581, 'Emphysema': 0.9154060578596902, 'Fibrosis': 0.8002758636055634, 'Pleural_Thickening': 0.7941462220742858, 'Hernia': 0.913444561586241}\n",
      "Overall AUROC for this fold: 0.8331856495656808\n",
      "Model for Fold 2 saved to /student/csc490_project/shared/cv_no_overlap/convnext_large.fb_in22k_fold2_model.pth\n",
      "\n",
      "--- Fold 3 ---\n",
      "Train patient IDs (first 5): [12681 13125 29707 24851 12409]\n",
      "Val patient IDs (first 5): [ 2997 21529 27358 26511 30662]\n",
      "Model: convnext_large.fb_in22k | Epoch 1/4 | Training Loss: 0.1847\n",
      "Model: convnext_large.fb_in22k | Epoch 2/4 | Training Loss: 0.1716\n",
      "Model: convnext_large.fb_in22k | Epoch 3/4 | Training Loss: 0.1636\n",
      "Model: convnext_large.fb_in22k | Epoch 4/4 | Training Loss: 0.1528\n",
      "Per-class AUROC for this fold: {'No Finding': 0.7793401601466727, 'Atelectasis': 0.8163217650186952, 'Cardiomegaly': 0.9167403164236704, 'Effusion': 0.881497293357122, 'Infiltration': 0.7089281995984098, 'Mass': 0.8564300639374126, 'Nodule': 0.7746552626879044, 'Pneumonia': 0.7691076659687429, 'Pneumothorax': 0.8747864763612142, 'Consolidation': 0.8048276436339341, 'Edema': 0.9095894263630425, 'Emphysema': 0.9242512945276192, 'Fibrosis': 0.8312088700486185, 'Pleural_Thickening': 0.7670587468749692, 'Hernia': 0.9119646634647367}\n",
      "Overall AUROC for this fold: 0.8351138565608509\n",
      "Model for Fold 3 saved to /student/csc490_project/shared/cv_no_overlap/convnext_large.fb_in22k_fold3_model.pth\n",
      "\n",
      "--- Fold 4 ---\n",
      "Train patient IDs (first 5): [12681 13125 29707 24851 12409]\n",
      "Val patient IDs (first 5): [ 8738  9217 23788 15582 10144]\n",
      "Model: convnext_large.fb_in22k | Epoch 1/4 | Training Loss: 0.1849\n",
      "Model: convnext_large.fb_in22k | Epoch 2/4 | Training Loss: 0.1720\n",
      "Model: convnext_large.fb_in22k | Epoch 3/4 | Training Loss: 0.1643\n",
      "Model: convnext_large.fb_in22k | Epoch 4/4 | Training Loss: 0.1541\n",
      "Per-class AUROC for this fold: {'No Finding': 0.7805831396494394, 'Atelectasis': 0.8096280727253846, 'Cardiomegaly': 0.8890426492093959, 'Effusion': 0.876158464019345, 'Infiltration': 0.7186055085625256, 'Mass': 0.8585768787698242, 'Nodule': 0.7832499708632673, 'Pneumonia': 0.7585236891121337, 'Pneumothorax': 0.8803270022350376, 'Consolidation': 0.79910993749498, 'Edema': 0.9047963032958972, 'Emphysema': 0.9238196206074911, 'Fibrosis': 0.8099378559781936, 'Pleural_Thickening': 0.8119663389538296, 'Hernia': 0.9159038752976835}\n",
      "Overall AUROC for this fold: 0.8346819537849619\n",
      "Model for Fold 4 saved to /student/csc490_project/shared/cv_no_overlap/convnext_large.fb_in22k_fold4_model.pth\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Extract unique patient IDs\n",
    "unique_patients = df[\"Patient ID\"].unique()\n",
    "\n",
    "# Shuffle them for reproducible random folds\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(unique_patients)\n",
    "\n",
    "# KFold on patient IDs: 4 folds\n",
    "n_splits = 4\n",
    "kf = KFold(n_splits=n_splits, shuffle=False)  # We already shuffled above\n",
    "\n",
    "# Create a list of (train_pat_idx, val_pat_idx) for each fold\n",
    "folds = list(kf.split(unique_patients))\n",
    "\n",
    "# Containers for per-fold results\n",
    "fold_overall_scores = []\n",
    "fold_class_scores = []\n",
    "fold_models = []\n",
    "\n",
    "for fold_idx, (train_pat_idx, val_pat_idx) in enumerate(folds):\n",
    "    print(f\"\\n--- Fold {fold_idx+1} ---\")\n",
    "    \n",
    "    # Identify patient IDs for training vs. validation\n",
    "    train_patients = unique_patients[train_pat_idx]\n",
    "    val_patients = unique_patients[val_pat_idx]\n",
    "    \n",
    "    # Print a few patient IDs to verify the split\n",
    "    print(f\"Train patient IDs (first 5): {train_patients[:5]}\")\n",
    "    print(f\"Val patient IDs (first 5): {val_patients[:5]}\")\n",
    "    \n",
    "    # Filter the main DataFrame by these patient IDs\n",
    "    train_fold_df = df[df[\"Patient ID\"].isin(train_patients)].reset_index(drop=True)\n",
    "    val_fold_df = df[df[\"Patient ID\"].isin(val_patients)].reset_index(drop=True)\n",
    "    \n",
    "    # Train and evaluate the model on this fold\n",
    "    model, auroc_per_class, overall_auroc = train_and_evaluate(\n",
    "        model_name, \n",
    "        train_fold_df, \n",
    "        val_fold_df, \n",
    "        epochs=7, \n",
    "        batch_size=16\n",
    "    )\n",
    "    \n",
    "    # Save results\n",
    "    fold_models.append(model)\n",
    "    fold_class_scores.append(auroc_per_class)\n",
    "    fold_overall_scores.append(overall_auroc)\n",
    "    \n",
    "    # Print fold results\n",
    "    print(\"Per-class AUROC for this fold:\", auroc_per_class)\n",
    "    print(\"Overall AUROC for this fold:\", overall_auroc)\n",
    "    \n",
    "    # Save the model for this fold\n",
    "    fold_model_save_path = f\"/student/csc490_project/shared/cv_no_overlap/{model_name}_fold{fold_idx+1}_model.pth\"\n",
    "    torch.save(model.state_dict(), fold_model_save_path)\n",
    "    print(f\"Model for Fold {fold_idx+1} saved to {fold_model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Cross Validation Results ===\n",
      "Fold 1 Overall AUROC: 0.8346\n",
      "Fold 2 Overall AUROC: 0.8332\n",
      "Fold 3 Overall AUROC: 0.8351\n",
      "Fold 4 Overall AUROC: 0.8347\n",
      "Average Overall AUROC: 0.8344\n",
      "Standard Deviation of Overall AUROC: 0.0007\n",
      "Average Per-class AUROC: {'No Finding': 0.7796647664441234, 'Atelectasis': 0.8139474783512521, 'Cardiomegaly': 0.9067686284839718, 'Effusion': 0.8785186645138724, 'Infiltration': 0.7175027508022653, 'Mass': 0.8538121226966325, 'Nodule': 0.7768716948323516, 'Pneumonia': 0.7600666072059874, 'Pneumothorax': 0.8753819845311552, 'Consolidation': 0.8033934446479009, 'Edema': 0.9006283458795437, 'Emphysema': 0.9209784631038654, 'Fibrosis': 0.8156073495145129, 'Pleural_Thickening': 0.7913509331251283, 'Hernia': 0.9215921999756649}\n"
     ]
    }
   ],
   "source": [
    "# Compute final metrics across folds\n",
    "avg_overall_auroc = np.mean(fold_overall_scores)\n",
    "std_overall_auroc = np.std(fold_overall_scores)\n",
    "\n",
    "print(\"\\n=== Final Cross Validation Results ===\")\n",
    "for i, score in enumerate(fold_overall_scores):\n",
    "    print(f\"Fold {i+1} Overall AUROC: {score:.4f}\")\n",
    "print(f\"Average Overall AUROC: {avg_overall_auroc:.4f}\")\n",
    "print(f\"Standard Deviation of Overall AUROC: {std_overall_auroc:.4f}\")\n",
    "\n",
    "# Compute average per-class AUROC\n",
    "avg_class_auroc = {}\n",
    "for class_name in CLASSES:\n",
    "    class_scores = [fold[class_name] for fold in fold_class_scores]\n",
    "    avg_class_auroc[class_name] = np.nanmean(class_scores)\n",
    "print(\"Average Per-class AUROC:\", avg_class_auroc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
