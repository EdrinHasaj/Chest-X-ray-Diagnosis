{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Combinations (Equal Weights Only):\n",
      "('maxvit', 'densenet', 'coatnet', 'swin', 'convnext'): Test AUROC = 0.8562, Val AUROC = 0.8435\n",
      "('maxvit', 'densenet', 'coatnet', 'convnext'): Test AUROC = 0.8557, Val AUROC = 0.8427\n",
      "('maxvit', 'densenet', 'coatnet', 'vgg19', 'swin', 'convnext'): Test AUROC = 0.8555, Val AUROC = 0.8434\n",
      "('maxvit', 'densenet', 'coatnet', 'vgg19', 'convnext'): Test AUROC = 0.8551, Val AUROC = 0.8428\n",
      "('maxvit', 'coatnet', 'swin', 'convnext'): Test AUROC = 0.8550, Val AUROC = 0.8416\n",
      "('maxvit', 'densenet', 'swin', 'convnext'): Test AUROC = 0.8550, Val AUROC = 0.8421\n",
      "('maxvit', 'coatnet', 'vgg19', 'swin', 'convnext'): Test AUROC = 0.8544, Val AUROC = 0.8419\n",
      "('maxvit', 'densenet', 'coatnet', 'swin'): Test AUROC = 0.8544, Val AUROC = 0.8420\n",
      "('maxvit', 'densenet', 'vgg19', 'swin', 'convnext'): Test AUROC = 0.8542, Val AUROC = 0.8426\n",
      "('maxvit', 'densenet', 'convnext'): Test AUROC = 0.8541, Val AUROC = 0.8407\n",
      "('maxvit', 'coatnet', 'convnext'): Test AUROC = 0.8538, Val AUROC = 0.8399\n",
      "('maxvit', 'densenet', 'vgg19', 'convnext'): Test AUROC = 0.8537, Val AUROC = 0.8418\n",
      "('maxvit', 'coatnet', 'vgg19', 'convnext'): Test AUROC = 0.8536, Val AUROC = 0.8407\n",
      "('maxvit', 'densenet', 'coatnet', 'vgg19', 'swin'): Test AUROC = 0.8535, Val AUROC = 0.8417\n",
      "('maxvit', 'densenet', 'coatnet'): Test AUROC = 0.8534, Val AUROC = 0.8406\n",
      "('maxvit', 'swin', 'convnext'): Test AUROC = 0.8531, Val AUROC = 0.8385\n",
      "('maxvit', 'densenet', 'coatnet', 'vgg19'): Test AUROC = 0.8527, Val AUROC = 0.8405\n",
      "('maxvit', 'vgg19', 'swin', 'convnext'): Test AUROC = 0.8526, Val AUROC = 0.8401\n",
      "('maxvit', 'coatnet', 'swin'): Test AUROC = 0.8523, Val AUROC = 0.8393\n",
      "('maxvit', 'densenet', 'swin'): Test AUROC = 0.8516, Val AUROC = 0.8402\n",
      "('maxvit', 'coatnet', 'vgg19', 'swin'): Test AUROC = 0.8515, Val AUROC = 0.8396\n",
      "('maxvit', 'vgg19', 'convnext'): Test AUROC = 0.8510, Val AUROC = 0.8381\n",
      "('densenet', 'coatnet', 'swin', 'convnext'): Test AUROC = 0.8508, Val AUROC = 0.8421\n",
      "('maxvit', 'densenet', 'vgg19', 'swin'): Test AUROC = 0.8508, Val AUROC = 0.8405\n",
      "('maxvit', 'convnext'): Test AUROC = 0.8500, Val AUROC = 0.8347\n",
      "('densenet', 'coatnet', 'vgg19', 'swin', 'convnext'): Test AUROC = 0.8499, Val AUROC = 0.8418\n",
      "('maxvit', 'coatnet'): Test AUROC = 0.8497, Val AUROC = 0.8360\n",
      "('maxvit', 'coatnet', 'vgg19'): Test AUROC = 0.8496, Val AUROC = 0.8372\n",
      "('maxvit', 'densenet'): Test AUROC = 0.8494, Val AUROC = 0.8373\n",
      "('densenet', 'coatnet', 'convnext'): Test AUROC = 0.8493, Val AUROC = 0.8409\n",
      "('maxvit', 'densenet', 'vgg19'): Test AUROC = 0.8492, Val AUROC = 0.8385\n",
      "('coatnet', 'swin', 'convnext'): Test AUROC = 0.8487, Val AUROC = 0.8396\n",
      "('densenet', 'coatnet', 'vgg19', 'convnext'): Test AUROC = 0.8486, Val AUROC = 0.8409\n",
      "('densenet', 'swin', 'convnext'): Test AUROC = 0.8485, Val AUROC = 0.8401\n",
      "('coatnet', 'vgg19', 'swin', 'convnext'): Test AUROC = 0.8479, Val AUROC = 0.8397\n",
      "('maxvit', 'swin'): Test AUROC = 0.8478, Val AUROC = 0.8345\n",
      "('densenet', 'vgg19', 'swin', 'convnext'): Test AUROC = 0.8476, Val AUROC = 0.8406\n",
      "('maxvit', 'vgg19', 'swin'): Test AUROC = 0.8475, Val AUROC = 0.8364\n",
      "('densenet', 'coatnet', 'swin'): Test AUROC = 0.8473, Val AUROC = 0.8394\n",
      "('densenet', 'coatnet', 'vgg19', 'swin'): Test AUROC = 0.8462, Val AUROC = 0.8390\n",
      "('coatnet', 'convnext'): Test AUROC = 0.8456, Val AUROC = 0.8366\n",
      "('coatnet', 'vgg19', 'convnext'): Test AUROC = 0.8455, Val AUROC = 0.8377\n",
      "('densenet', 'vgg19', 'convnext'): Test AUROC = 0.8455, Val AUROC = 0.8391\n",
      "('densenet', 'convnext'): Test AUROC = 0.8454, Val AUROC = 0.8371\n",
      "('swin', 'convnext'): Test AUROC = 0.8452, Val AUROC = 0.8347\n",
      "('vgg19', 'swin', 'convnext'): Test AUROC = 0.8445, Val AUROC = 0.8369\n",
      "('densenet', 'coatnet'): Test AUROC = 0.8442, Val AUROC = 0.8365\n",
      "('densenet', 'coatnet', 'vgg19'): Test AUROC = 0.8434, Val AUROC = 0.8365\n",
      "('maxvit', 'vgg19'): Test AUROC = 0.8429, Val AUROC = 0.8305\n",
      "('coatnet', 'swin'): Test AUROC = 0.8428, Val AUROC = 0.8357\n",
      "('coatnet', 'vgg19', 'swin'): Test AUROC = 0.8421, Val AUROC = 0.8357\n",
      "('densenet', 'swin'): Test AUROC = 0.8416, Val AUROC = 0.8361\n",
      "('densenet', 'vgg19', 'swin'): Test AUROC = 0.8410, Val AUROC = 0.8366\n",
      "('vgg19', 'convnext'): Test AUROC = 0.8395, Val AUROC = 0.8326\n",
      "('coatnet', 'vgg19'): Test AUROC = 0.8356, Val AUROC = 0.8299\n",
      "('densenet', 'vgg19'): Test AUROC = 0.8347, Val AUROC = 0.8316\n",
      "('vgg19', 'swin'): Test AUROC = 0.8325, Val AUROC = 0.8292\n",
      "\n",
      "Best Combination: ('maxvit', 'densenet', 'coatnet', 'swin', 'convnext')\n",
      "Best Weights (equal): [0.2 0.2 0.2 0.2 0.2]\n",
      "Best Test AUROC: 0.8562\n",
      "Best Val AUROC: 0.8435\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import timm\n",
    "\n",
    "# Define the 15 disease classes\n",
    "CLASSES = [\n",
    "    \"No Finding\", \"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\",\n",
    "    \"Mass\", \"Nodule\", \"Pneumonia\", \"Pneumothorax\", \"Consolidation\",\n",
    "    \"Edema\", \"Emphysema\", \"Fibrosis\", \"Pleural_Thickening\", \"Hernia\"\n",
    "]\n",
    "\n",
    "# Load and preprocess labels\n",
    "df = pd.read_csv(\"/student/csc490_project/shared/labels.csv\")\n",
    "df[\"label_list\"] = df[\"Finding Labels\"].apply(lambda x: x.split(\"|\"))\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=CLASSES)\n",
    "labels_array = mlb.fit_transform(df[\"label_list\"])\n",
    "df[\"labels\"] = list(labels_array)\n",
    "\n",
    "# Patient-level split into train, val, test\n",
    "unique_patients = df[\"Patient ID\"].unique()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(unique_patients)\n",
    "\n",
    "train_end = int(0.7 * len(unique_patients))\n",
    "val_end = int(0.8 * len(unique_patients))\n",
    "\n",
    "train_df = df[df[\"Patient ID\"].isin(unique_patients[:train_end])].reset_index(drop=True)\n",
    "val_df = df[df[\"Patient ID\"].isin(unique_patients[train_end:val_end])].reset_index(drop=True)\n",
    "test_df = df[df[\"Patient ID\"].isin(unique_patients[val_end:])].reset_index(drop=True)\n",
    "\n",
    "class ChestXrayDataset(Dataset):\n",
    "    \"\"\"Custom Dataset class for Chest X-ray images.\"\"\"\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.df.iloc[idx][\"Image Index\"])\n",
    "        image = Image.open(img_path).convert(\"L\")  # Convert to grayscale\n",
    "        labels = torch.tensor(self.df.iloc[idx][\"labels\"], dtype=torch.float)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, labels\n",
    "\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define dataloaders\n",
    "img_dir = \"/student/csc490_project/shared/preprocessed_images/preprocessed_images\"\n",
    "train_dataset = ChestXrayDataset(train_df, img_dir, train_transform)\n",
    "val_dataset = ChestXrayDataset(val_df, img_dir, val_transform)\n",
    "test_dataset = ChestXrayDataset(test_df, img_dir, val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "# Load models and weights\n",
    "models = {\n",
    "    'maxvit': timm.create_model('maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k', pretrained=False, num_classes=15),\n",
    "    'densenet': timm.create_model('densenet121', pretrained=False, num_classes=15),\n",
    "    'coatnet': timm.create_model('coatnet_2_rw_224.sw_in12k_ft_in1k', pretrained=False, num_classes=15),\n",
    "    'vgg19': timm.create_model('vgg19.tv_in1k', pretrained=False, num_classes=15),\n",
    "    'swin': timm.create_model('swin_large_patch4_window7_224', pretrained=False, num_classes=15),\n",
    "    'convnext': timm.create_model('convnext_large.fb_in22k', pretrained=False, num_classes=15)\n",
    "}\n",
    "\n",
    "# Load pretrained weights\n",
    "models['maxvit'].load_state_dict(torch.load('/student/csc490_project/shared/new_split_models/no_augment_maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k_model.pth'))\n",
    "models['densenet'].load_state_dict(torch.load('/student/csc490_project/shared/new_split_models/no_augment_densenet121_model.pth'))\n",
    "models['coatnet'].load_state_dict(torch.load('/student/csc490_project/shared/new_split_models/no_augment_coatnet_2_rw_224.sw_in12k_ft_in1k_model.pth'))\n",
    "models['swin'].load_state_dict(torch.load('/student/csc490_project/shared/new_split_models/no_augment_swin_large_patch4_window7_224_model.pth'))\n",
    "models['convnext'].load_state_dict(torch.load('/student/csc490_project/shared/new_split_models/no_augment_convnext_large.fb_in22k_model.pth'))\n",
    "models['vgg19'].load_state_dict(torch.load('/student/csc490_project/shared/new_split_models/no_augment_vgg19.tv_in1k_model.pth'))\n",
    "\n",
    "# Move models to device and set to eval mode\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "for model in models.values():\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "def collect_predictions(loader):\n",
    "    \"\"\"\n",
    "    Collects sigmoid predictions and labels from the provided DataLoader.\n",
    "\n",
    "    Args:\n",
    "        loader (DataLoader): DataLoader to get images and labels from.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Dict[str, np.ndarray], np.ndarray]:\n",
    "            - Dictionary of model name to predictions.\n",
    "            - Numpy array of true labels.\n",
    "    \"\"\"\n",
    "    all_preds = {name: [] for name in models}\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            for name, model in models.items():\n",
    "                all_preds[name].append(torch.sigmoid(model(images)).cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    all_preds = {k: np.concatenate(v) for k, v in all_preds.items()}\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    return all_preds, all_labels\n",
    "\n",
    "# Get predictions\n",
    "train_preds, train_labels = collect_predictions(train_loader)\n",
    "val_preds, val_labels = collect_predictions(val_loader)\n",
    "test_preds, test_labels = collect_predictions(test_loader)\n",
    "\n",
    "# Evaluate equal-weighted ensemble combinations\n",
    "results = []\n",
    "\n",
    "for r in range(2, len(models) + 1):\n",
    "    for combination in itertools.combinations(models.keys(), r):\n",
    "        preds_val = [val_preds[model] for model in combination]\n",
    "        preds_test = [test_preds[model] for model in combination]\n",
    "\n",
    "        weights = np.ones(len(combination)) / len(combination)\n",
    "\n",
    "        combined_val = sum(weights[i] * preds_val[i] for i in range(len(combination)))\n",
    "        combined_test = sum(weights[i] * preds_test[i] for i in range(len(combination)))\n",
    "\n",
    "        val_auroc = np.mean([\n",
    "            roc_auc_score(val_labels[:, i], combined_val[:, i]) for i in range(15)\n",
    "        ])\n",
    "        test_auroc = np.mean([\n",
    "            roc_auc_score(test_labels[:, i], combined_test[:, i]) for i in range(15)\n",
    "        ])\n",
    "\n",
    "        results.append({\n",
    "            'combination': combination,\n",
    "            'weights': weights,\n",
    "            'val_auroc': val_auroc,\n",
    "            'test_auroc': test_auroc\n",
    "        })\n",
    "\n",
    "# Sort combinations by test AUROC\n",
    "results = sorted(results, key=lambda x: x['test_auroc'], reverse=True)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nAll Combinations (Equal Weights Only):\")\n",
    "for res in results:\n",
    "    print(f\"{res['combination']}: Test AUROC = {res['test_auroc']:.4f}, Val AUROC = {res['val_auroc']:.4f}\")\n",
    "\n",
    "# Print best result\n",
    "best = results[0]\n",
    "print(f\"\\nBest Combination: {best['combination']}\")\n",
    "print(f\"Best Weights (equal): {best['weights']}\")\n",
    "print(f\"Best Test AUROC: {best['test_auroc']:.4f}\")\n",
    "print(f\"Best Val AUROC: {best['val_auroc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TTA-Based Ensemble Evaluation\n",
      "Used Models: ['maxvit', 'densenet', 'coatnet', 'swin', 'convnext']\n",
      "Equal Weights: [0.2 0.2 0.2 0.2 0.2]\n",
      "\n",
      "Mean Test AUROC (TTA): 0.8571\n",
      "\n",
      "Per-Class Test AUROC (TTA):\n",
      "No Finding: 0.8018\n",
      "Atelectasis: 0.8369\n",
      "Cardiomegaly: 0.9168\n",
      "Effusion: 0.8953\n",
      "Infiltration: 0.7375\n",
      "Mass: 0.8829\n",
      "Nodule: 0.8105\n",
      "Pneumonia: 0.7887\n",
      "Pneumothorax: 0.8962\n",
      "Consolidation: 0.8200\n",
      "Edema: 0.9157\n",
      "Emphysema: 0.9445\n",
      "Fibrosis: 0.8474\n",
      "Pleural_Thickening: 0.8447\n",
      "Hernia: 0.9185\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Define Test-Time Augmentation (TTA) Transforms\n",
    "# ----------------------------------------------------\n",
    "# Each transform represents a different augmentation strategy that will be used during inference\n",
    "\n",
    "tta_transforms = [\n",
    "    transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=1.0),  # Always flip\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1),  # Slight color variation\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.02, 0.02)),  # Minor translation\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Function to Collect TTA Predictions from Models\n",
    "# ----------------------------------------------------\n",
    "def collect_tta_predictions(df, root_dir, models, device, tta_transforms, batch_size=16):\n",
    "    \"\"\"\n",
    "    Collect predictions from multiple models using Test-Time Augmentation (TTA).\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing image paths and labels.\n",
    "        root_dir (str): Path to image directory.\n",
    "        models (dict): Dictionary of model name to model object.\n",
    "        device (torch.device): Device to run inference on (e.g., 'cuda' or 'cpu').\n",
    "        tta_transforms (list): List of torchvision transforms for TTA.\n",
    "        batch_size (int): Batch size for DataLoader.\n",
    "    \n",
    "    Returns:\n",
    "        all_preds_avg (dict): Dictionary of model name to average TTA predictions [num_samples x num_classes].\n",
    "        all_labels (np.ndarray): Ground truth labels [num_samples x num_classes].\n",
    "    \"\"\"\n",
    "    all_preds = {name: [] for name in models}  # Store predictions for each model across TTA versions\n",
    "    all_labels_tta = []  # Labels collected per TTA to ensure consistency\n",
    "\n",
    "    # Iterate through each TTA transform\n",
    "    for tform in tta_transforms:\n",
    "        # Load dataset using the current TTA transform\n",
    "        loader = DataLoader(\n",
    "            ChestXrayDataset(df, root_dir, tform),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "        preds_this_tta = {name: [] for name in models}\n",
    "        labels_this_tta = []\n",
    "\n",
    "        # Disable gradient computation for inference\n",
    "        with torch.no_grad():\n",
    "            for images, labels in loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Run each model on the current TTA-transformed batch\n",
    "                for name in models:\n",
    "                    logits = models[name](images)\n",
    "                    probs = torch.sigmoid(logits).cpu().numpy()  # Convert to probabilities\n",
    "                    preds_this_tta[name].append(probs)\n",
    "\n",
    "                labels_this_tta.append(labels.cpu().numpy())\n",
    "\n",
    "        # Aggregate predictions and labels from this TTA version\n",
    "        for name in models:\n",
    "            preds_concat = np.concatenate(preds_this_tta[name], axis=0)\n",
    "            all_preds[name].append(preds_concat)\n",
    "\n",
    "        labels_concat = np.concatenate(labels_this_tta, axis=0)\n",
    "        all_labels_tta.append(labels_concat)\n",
    "\n",
    "    # Ensure labels are consistent across TTA versions\n",
    "    for i in range(1, len(all_labels_tta)):\n",
    "        if all_labels_tta[i].shape != all_labels_tta[0].shape or not np.array_equal(all_labels_tta[i], all_labels_tta[0]):\n",
    "            raise ValueError(\"Label mismatch across TTAs â€” check data consistency.\")\n",
    "    \n",
    "    all_labels = all_labels_tta[0]\n",
    "\n",
    "    # Compute average predictions across TTA versions\n",
    "    all_preds_avg = {}\n",
    "    for name in models:\n",
    "        stacked = np.stack(all_preds[name], axis=0)  # Shape: [num_ttas, num_samples, num_classes]\n",
    "        all_preds_avg[name] = np.mean(stacked, axis=0)  # Average across TTA runs\n",
    "\n",
    "    return all_preds_avg, all_labels\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Run TTA-Based Ensemble Inference\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# List of best performing models to use for ensemble\n",
    "best_models = ['maxvit', 'densenet', 'coatnet', 'swin', 'convnext']\n",
    "\n",
    "# Assign equal weights for averaging predictions\n",
    "equal_weights = np.array([0.2] * len(best_models))\n",
    "\n",
    "# Select only the models specified in `best_models`\n",
    "selected_models = {name: models[name] for name in best_models}\n",
    "\n",
    "# Get averaged TTA predictions and labels\n",
    "test_preds_tta, test_labels_tta = collect_tta_predictions(\n",
    "    df=test_df,\n",
    "    root_dir=img_dir,\n",
    "    models=selected_models,\n",
    "    device=device,\n",
    "    tta_transforms=tta_transforms\n",
    ")\n",
    "\n",
    "# Compute final ensemble predictions by weighted average\n",
    "ensemble_test_preds_tta = sum(\n",
    "    w * test_preds_tta[name] for w, name in zip(equal_weights, best_models)\n",
    ")\n",
    "\n",
    "# Compute AUROC for each class and overall mean\n",
    "per_class_aurocs_tta = [\n",
    "    roc_auc_score(test_labels_tta[:, i], ensemble_test_preds_tta[:, i])\n",
    "    for i in range(test_labels_tta.shape[1])\n",
    "]\n",
    "mean_test_auroc_tta = np.mean(per_class_aurocs_tta)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Print TTA Evaluation Results\n",
    "# ----------------------------------------------------\n",
    "print(\"\\nTTA-Based Ensemble Evaluation\")\n",
    "print(f\"Used Models: {best_models}\")\n",
    "print(f\"Equal Weights: {equal_weights}\")\n",
    "print(f\"\\nMean Test AUROC (TTA): {mean_test_auroc_tta:.4f}\")\n",
    "print(\"\\nPer-Class Test AUROC (TTA):\")\n",
    "for cls, auc in zip(CLASSES, per_class_aurocs_tta):\n",
    "    print(f\"{cls}: {auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
