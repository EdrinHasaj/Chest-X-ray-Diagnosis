{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for gamma=0.6\n",
      "Training coatnet_2_rw_224.sw_in12k_ft_in1k with gamma=0.6...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c556d4cba034106bff4698c96947ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/296M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Gamma: 0.6 - Train Loss: 0.1998 - Val Loss: 0.1891 - Val AUROC: 0.7596\n",
      "Epoch 2/25 - Gamma: 0.6 - Train Loss: 0.1876 - Val Loss: 0.1889 - Val AUROC: 0.7824\n",
      "Epoch 3/25 - Gamma: 0.6 - Train Loss: 0.1824 - Val Loss: 0.1822 - Val AUROC: 0.7959\n",
      "Epoch 4/25 - Gamma: 0.6 - Train Loss: 0.1792 - Val Loss: 0.1799 - Val AUROC: 0.8028\n",
      "Epoch 5/25 - Gamma: 0.6 - Train Loss: 0.1764 - Val Loss: 0.1788 - Val AUROC: 0.8125\n",
      "Epoch 6/25 - Gamma: 0.6 - Train Loss: 0.1743 - Val Loss: 0.1785 - Val AUROC: 0.8144\n",
      "Epoch 7/25 - Gamma: 0.6 - Train Loss: 0.1724 - Val Loss: 0.1772 - Val AUROC: 0.8204\n",
      "Epoch 8/25 - Gamma: 0.6 - Train Loss: 0.1708 - Val Loss: 0.1770 - Val AUROC: 0.8177\n",
      "Epoch 9/25 - Gamma: 0.6 - Train Loss: 0.1692 - Val Loss: 0.1746 - Val AUROC: 0.8231\n",
      "Epoch 10/25 - Gamma: 0.6 - Train Loss: 0.1675 - Val Loss: 0.1746 - Val AUROC: 0.8244\n",
      "Epoch 11/25 - Gamma: 0.6 - Train Loss: 0.1657 - Val Loss: 0.1780 - Val AUROC: 0.8202\n",
      "Epoch 12/25 - Gamma: 0.6 - Train Loss: 0.1643 - Val Loss: 0.1748 - Val AUROC: 0.8235\n",
      "Training convnext_large.fb_in22k with gamma=0.6...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda5f1bb612646c0a7623f90516183c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/919M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Gamma: 0.6 - Train Loss: 0.1860 - Val Loss: 0.1765 - Val AUROC: 0.8142\n",
      "Epoch 2/25 - Gamma: 0.6 - Train Loss: 0.1731 - Val Loss: 0.1738 - Val AUROC: 0.8241\n",
      "Epoch 3/25 - Gamma: 0.6 - Train Loss: 0.1653 - Val Loss: 0.1734 - Val AUROC: 0.8268\n",
      "Epoch 4/25 - Gamma: 0.6 - Train Loss: 0.1550 - Val Loss: 0.1745 - Val AUROC: 0.8256\n",
      "Epoch 5/25 - Gamma: 0.6 - Train Loss: 0.1389 - Val Loss: 0.1909 - Val AUROC: 0.8073\n",
      "Training densenet121 with gamma=0.6...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d388ce81424fb7bce00c7569a7f594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/32.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Gamma: 0.6 - Train Loss: 0.1932 - Val Loss: 0.1835 - Val AUROC: 0.7822\n",
      "Epoch 2/25 - Gamma: 0.6 - Train Loss: 0.1803 - Val Loss: 0.1794 - Val AUROC: 0.8069\n",
      "Epoch 3/25 - Gamma: 0.6 - Train Loss: 0.1763 - Val Loss: 0.1785 - Val AUROC: 0.8072\n",
      "Epoch 4/25 - Gamma: 0.6 - Train Loss: 0.1729 - Val Loss: 0.1770 - Val AUROC: 0.8156\n",
      "Epoch 5/25 - Gamma: 0.6 - Train Loss: 0.1699 - Val Loss: 0.1761 - Val AUROC: 0.8159\n",
      "Epoch 6/25 - Gamma: 0.6 - Train Loss: 0.1670 - Val Loss: 0.1753 - Val AUROC: 0.8150\n",
      "Epoch 7/25 - Gamma: 0.6 - Train Loss: 0.1643 - Val Loss: 0.1782 - Val AUROC: 0.8106\n",
      "Training maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k with gamma=0.6...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b343479f864a48e8b6d03fc4d7b628c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/465M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Gamma: 0.6 - Train Loss: 0.1890 - Val Loss: 0.1843 - Val AUROC: 0.7916\n",
      "Epoch 2/25 - Gamma: 0.6 - Train Loss: 0.1776 - Val Loss: 0.1780 - Val AUROC: 0.8114\n",
      "Epoch 3/25 - Gamma: 0.6 - Train Loss: 0.1729 - Val Loss: 0.1751 - Val AUROC: 0.8203\n",
      "Epoch 4/25 - Gamma: 0.6 - Train Loss: 0.1689 - Val Loss: 0.1734 - Val AUROC: 0.8247\n",
      "Epoch 5/25 - Gamma: 0.6 - Train Loss: 0.1652 - Val Loss: 0.1739 - Val AUROC: 0.8252\n",
      "Epoch 6/25 - Gamma: 0.6 - Train Loss: 0.1612 - Val Loss: 0.1753 - Val AUROC: 0.8293\n",
      "Epoch 7/25 - Gamma: 0.6 - Train Loss: 0.1568 - Val Loss: 0.1756 - Val AUROC: 0.8244\n",
      "Epoch 8/25 - Gamma: 0.6 - Train Loss: 0.1512 - Val Loss: 0.1831 - Val AUROC: 0.8148\n",
      "Training swin_large_patch4_window7_224 with gamma=0.6...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2dadc7fb07490fae71aabae907dbaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/788M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Gamma: 0.6 - Train Loss: 0.1917 - Val Loss: 0.1815 - Val AUROC: 0.7964\n",
      "Epoch 2/25 - Gamma: 0.6 - Train Loss: 0.1803 - Val Loss: 0.1767 - Val AUROC: 0.8073\n",
      "Epoch 3/25 - Gamma: 0.6 - Train Loss: 0.1765 - Val Loss: 0.1748 - Val AUROC: 0.8193\n",
      "Epoch 4/25 - Gamma: 0.6 - Train Loss: 0.1724 - Val Loss: 0.1771 - Val AUROC: 0.8154\n",
      "Epoch 5/25 - Gamma: 0.6 - Train Loss: 0.1694 - Val Loss: 0.1758 - Val AUROC: 0.8182\n",
      "Training vgg19.tv_in1k with gamma=0.6...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c531d56b82684be0927209c91fd49b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/575M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Gamma: 0.6 - Train Loss: 0.2007 - Val Loss: 0.1933 - Val AUROC: 0.7446\n",
      "Epoch 2/25 - Gamma: 0.6 - Train Loss: 0.1916 - Val Loss: 0.1870 - Val AUROC: 0.7683\n",
      "Epoch 3/25 - Gamma: 0.6 - Train Loss: 0.1869 - Val Loss: 0.1838 - Val AUROC: 0.7781\n",
      "Epoch 4/25 - Gamma: 0.6 - Train Loss: 0.1834 - Val Loss: 0.1826 - Val AUROC: 0.7800\n",
      "Epoch 5/25 - Gamma: 0.6 - Train Loss: 0.1809 - Val Loss: 0.1797 - Val AUROC: 0.7909\n",
      "Epoch 6/25 - Gamma: 0.6 - Train Loss: 0.1790 - Val Loss: 0.1795 - Val AUROC: 0.7928\n",
      "Epoch 7/25 - Gamma: 0.6 - Train Loss: 0.1772 - Val Loss: 0.1786 - Val AUROC: 0.8005\n",
      "Epoch 8/25 - Gamma: 0.6 - Train Loss: 0.1755 - Val Loss: 0.1799 - Val AUROC: 0.7909\n",
      "Epoch 9/25 - Gamma: 0.6 - Train Loss: 0.1740 - Val Loss: 0.1778 - Val AUROC: 0.8026\n",
      "Epoch 10/25 - Gamma: 0.6 - Train Loss: 0.1726 - Val Loss: 0.1807 - Val AUROC: 0.7990\n",
      "Epoch 11/25 - Gamma: 0.6 - Train Loss: 0.1712 - Val Loss: 0.1786 - Val AUROC: 0.7990\n",
      "Finished training for gamma=0.6, saved to '/student/csc490_project/shared/training_gamma/training_gamma_0.6'\n",
      "Starting training for gamma=0.8\n",
      "Training coatnet_2_rw_224.sw_in12k_ft_in1k with gamma=0.8...\n",
      "Epoch 1/25 - Gamma: 0.8 - Train Loss: 0.1974 - Val Loss: 0.1861 - Val AUROC: 0.7682\n",
      "Epoch 2/25 - Gamma: 0.8 - Train Loss: 0.1858 - Val Loss: 0.1796 - Val AUROC: 0.7920\n",
      "Epoch 3/25 - Gamma: 0.8 - Train Loss: 0.1810 - Val Loss: 0.1780 - Val AUROC: 0.8068\n",
      "Epoch 4/25 - Gamma: 0.8 - Train Loss: 0.1781 - Val Loss: 0.1771 - Val AUROC: 0.8150\n",
      "Epoch 5/25 - Gamma: 0.8 - Train Loss: 0.1753 - Val Loss: 0.1749 - Val AUROC: 0.8158\n",
      "Epoch 6/25 - Gamma: 0.8 - Train Loss: 0.1731 - Val Loss: 0.1755 - Val AUROC: 0.8227\n",
      "Epoch 7/25 - Gamma: 0.8 - Train Loss: 0.1710 - Val Loss: 0.1735 - Val AUROC: 0.8276\n",
      "Epoch 8/25 - Gamma: 0.8 - Train Loss: 0.1691 - Val Loss: 0.1722 - Val AUROC: 0.8327\n",
      "Epoch 9/25 - Gamma: 0.8 - Train Loss: 0.1675 - Val Loss: 0.1726 - Val AUROC: 0.8338\n",
      "Epoch 10/25 - Gamma: 0.8 - Train Loss: 0.1655 - Val Loss: 0.1747 - Val AUROC: 0.8276\n",
      "Epoch 11/25 - Gamma: 0.8 - Train Loss: 0.1640 - Val Loss: 0.1739 - Val AUROC: 0.8292\n",
      "Training convnext_large.fb_in22k with gamma=0.8...\n",
      "Epoch 1/25 - Gamma: 0.8 - Train Loss: 0.1860 - Val Loss: 0.1771 - Val AUROC: 0.8064\n",
      "Epoch 2/25 - Gamma: 0.8 - Train Loss: 0.1728 - Val Loss: 0.1736 - Val AUROC: 0.8287\n",
      "Epoch 3/25 - Gamma: 0.8 - Train Loss: 0.1653 - Val Loss: 0.1732 - Val AUROC: 0.8307\n",
      "Epoch 4/25 - Gamma: 0.8 - Train Loss: 0.1550 - Val Loss: 0.1775 - Val AUROC: 0.8238\n",
      "Epoch 5/25 - Gamma: 0.8 - Train Loss: 0.1389 - Val Loss: 0.1850 - Val AUROC: 0.8163\n",
      "Training densenet121 with gamma=0.8...\n",
      "Epoch 1/25 - Gamma: 0.8 - Train Loss: 0.1953 - Val Loss: 0.1817 - Val AUROC: 0.7878\n",
      "Epoch 2/25 - Gamma: 0.8 - Train Loss: 0.1807 - Val Loss: 0.1776 - Val AUROC: 0.8108\n",
      "Epoch 3/25 - Gamma: 0.8 - Train Loss: 0.1766 - Val Loss: 0.1782 - Val AUROC: 0.8127\n",
      "Epoch 4/25 - Gamma: 0.8 - Train Loss: 0.1732 - Val Loss: 0.1753 - Val AUROC: 0.8219\n",
      "Epoch 5/25 - Gamma: 0.8 - Train Loss: 0.1703 - Val Loss: 0.1745 - Val AUROC: 0.8235\n",
      "Epoch 6/25 - Gamma: 0.8 - Train Loss: 0.1676 - Val Loss: 0.1742 - Val AUROC: 0.8242\n",
      "Epoch 7/25 - Gamma: 0.8 - Train Loss: 0.1650 - Val Loss: 0.1750 - Val AUROC: 0.8245\n",
      "Epoch 8/25 - Gamma: 0.8 - Train Loss: 0.1624 - Val Loss: 0.1775 - Val AUROC: 0.8194\n",
      "Epoch 9/25 - Gamma: 0.8 - Train Loss: 0.1593 - Val Loss: 0.1787 - Val AUROC: 0.8180\n",
      "Training maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k with gamma=0.8...\n",
      "Epoch 1/25 - Gamma: 0.8 - Train Loss: 0.1904 - Val Loss: 0.1798 - Val AUROC: 0.8059\n",
      "Epoch 2/25 - Gamma: 0.8 - Train Loss: 0.1786 - Val Loss: 0.1755 - Val AUROC: 0.8172\n",
      "Epoch 3/25 - Gamma: 0.8 - Train Loss: 0.1735 - Val Loss: 0.1727 - Val AUROC: 0.8276\n",
      "Epoch 4/25 - Gamma: 0.8 - Train Loss: 0.1699 - Val Loss: 0.1737 - Val AUROC: 0.8298\n",
      "Epoch 5/25 - Gamma: 0.8 - Train Loss: 0.1663 - Val Loss: 0.1721 - Val AUROC: 0.8318\n",
      "Epoch 6/25 - Gamma: 0.8 - Train Loss: 0.1628 - Val Loss: 0.1735 - Val AUROC: 0.8265\n",
      "Epoch 7/25 - Gamma: 0.8 - Train Loss: 0.1583 - Val Loss: 0.1734 - Val AUROC: 0.8318\n",
      "Training swin_large_patch4_window7_224 with gamma=0.8...\n",
      "Epoch 1/25 - Gamma: 0.8 - Train Loss: 0.1912 - Val Loss: 0.1829 - Val AUROC: 0.7797\n",
      "Epoch 2/25 - Gamma: 0.8 - Train Loss: 0.1805 - Val Loss: 0.1771 - Val AUROC: 0.8120\n",
      "Epoch 3/25 - Gamma: 0.8 - Train Loss: 0.1762 - Val Loss: 0.1764 - Val AUROC: 0.8150\n",
      "Epoch 4/25 - Gamma: 0.8 - Train Loss: 0.1730 - Val Loss: 0.1738 - Val AUROC: 0.8240\n",
      "Epoch 5/25 - Gamma: 0.8 - Train Loss: 0.1699 - Val Loss: 0.1734 - Val AUROC: 0.8233\n",
      "Epoch 6/25 - Gamma: 0.8 - Train Loss: 0.1666 - Val Loss: 0.1748 - Val AUROC: 0.8243\n",
      "Epoch 7/25 - Gamma: 0.8 - Train Loss: 0.1628 - Val Loss: 0.1741 - Val AUROC: 0.8233\n",
      "Epoch 8/25 - Gamma: 0.8 - Train Loss: 0.1591 - Val Loss: 0.1762 - Val AUROC: 0.8253\n",
      "Epoch 9/25 - Gamma: 0.8 - Train Loss: 0.1546 - Val Loss: 0.1794 - Val AUROC: 0.8179\n",
      "Epoch 10/25 - Gamma: 0.8 - Train Loss: 0.1492 - Val Loss: 0.1835 - Val AUROC: 0.8122\n",
      "Training vgg19.tv_in1k with gamma=0.8...\n",
      "Epoch 1/25 - Gamma: 0.8 - Train Loss: 0.2014 - Val Loss: 0.2000 - Val AUROC: 0.7353\n",
      "Epoch 2/25 - Gamma: 0.8 - Train Loss: 0.1928 - Val Loss: 0.1883 - Val AUROC: 0.7582\n",
      "Epoch 3/25 - Gamma: 0.8 - Train Loss: 0.1876 - Val Loss: 0.1856 - Val AUROC: 0.7740\n",
      "Epoch 4/25 - Gamma: 0.8 - Train Loss: 0.1846 - Val Loss: 0.1820 - Val AUROC: 0.7898\n",
      "Epoch 5/25 - Gamma: 0.8 - Train Loss: 0.1823 - Val Loss: 0.1798 - Val AUROC: 0.7972\n",
      "Epoch 6/25 - Gamma: 0.8 - Train Loss: 0.1799 - Val Loss: 0.1818 - Val AUROC: 0.7896\n",
      "Epoch 7/25 - Gamma: 0.8 - Train Loss: 0.1779 - Val Loss: 0.1785 - Val AUROC: 0.8014\n",
      "Epoch 8/25 - Gamma: 0.8 - Train Loss: 0.1762 - Val Loss: 0.1835 - Val AUROC: 0.7948\n",
      "Epoch 9/25 - Gamma: 0.8 - Train Loss: 0.1749 - Val Loss: 0.1773 - Val AUROC: 0.8051\n",
      "Epoch 10/25 - Gamma: 0.8 - Train Loss: 0.1735 - Val Loss: 0.1785 - Val AUROC: 0.8040\n",
      "Epoch 11/25 - Gamma: 0.8 - Train Loss: 0.1719 - Val Loss: 0.1776 - Val AUROC: 0.8061\n",
      "Epoch 12/25 - Gamma: 0.8 - Train Loss: 0.1704 - Val Loss: 0.1782 - Val AUROC: 0.8085\n",
      "Epoch 13/25 - Gamma: 0.8 - Train Loss: 0.1690 - Val Loss: 0.1788 - Val AUROC: 0.8077\n",
      "Epoch 14/25 - Gamma: 0.8 - Train Loss: 0.1677 - Val Loss: 0.1760 - Val AUROC: 0.8112\n",
      "Epoch 15/25 - Gamma: 0.8 - Train Loss: 0.1660 - Val Loss: 0.1787 - Val AUROC: 0.8078\n",
      "Epoch 16/25 - Gamma: 0.8 - Train Loss: 0.1642 - Val Loss: 0.1788 - Val AUROC: 0.8104\n",
      "Finished training for gamma=0.8, saved to '/student/csc490_project/shared/training_gamma/training_gamma_0.8'\n",
      "Starting training for gamma=1.0\n",
      "Training coatnet_2_rw_224.sw_in12k_ft_in1k with gamma=1.0...\n",
      "Epoch 1/25 - Gamma: 1.0 - Train Loss: 0.1962 - Val Loss: 0.1890 - Val AUROC: 0.7791\n",
      "Epoch 2/25 - Gamma: 1.0 - Train Loss: 0.1849 - Val Loss: 0.1832 - Val AUROC: 0.7955\n",
      "Epoch 3/25 - Gamma: 1.0 - Train Loss: 0.1804 - Val Loss: 0.1752 - Val AUROC: 0.8182\n",
      "Epoch 4/25 - Gamma: 1.0 - Train Loss: 0.1775 - Val Loss: 0.1755 - Val AUROC: 0.8188\n",
      "Epoch 5/25 - Gamma: 1.0 - Train Loss: 0.1749 - Val Loss: 0.1742 - Val AUROC: 0.8278\n",
      "Epoch 6/25 - Gamma: 1.0 - Train Loss: 0.1723 - Val Loss: 0.1757 - Val AUROC: 0.8206\n",
      "Epoch 7/25 - Gamma: 1.0 - Train Loss: 0.1711 - Val Loss: 0.1716 - Val AUROC: 0.8319\n",
      "Epoch 8/25 - Gamma: 1.0 - Train Loss: 0.1691 - Val Loss: 0.1747 - Val AUROC: 0.8305\n",
      "Epoch 9/25 - Gamma: 1.0 - Train Loss: 0.1997 - Val Loss: 0.2166 - Val AUROC: 0.5366\n",
      "Training convnext_large.fb_in22k with gamma=1.0...\n",
      "Epoch 1/25 - Gamma: 1.0 - Train Loss: 0.1860 - Val Loss: 0.1865 - Val AUROC: 0.8137\n",
      "Epoch 2/25 - Gamma: 1.0 - Train Loss: 0.1726 - Val Loss: 0.1718 - Val AUROC: 0.8307\n",
      "Epoch 3/25 - Gamma: 1.0 - Train Loss: 0.1644 - Val Loss: 0.1717 - Val AUROC: 0.8316\n",
      "Epoch 4/25 - Gamma: 1.0 - Train Loss: 0.1532 - Val Loss: 0.1778 - Val AUROC: 0.8248\n",
      "Epoch 5/25 - Gamma: 1.0 - Train Loss: 0.1354 - Val Loss: 0.1879 - Val AUROC: 0.8123\n",
      "Training densenet121 with gamma=1.0...\n",
      "Epoch 1/25 - Gamma: 1.0 - Train Loss: 0.1946 - Val Loss: 0.1795 - Val AUROC: 0.7991\n",
      "Epoch 2/25 - Gamma: 1.0 - Train Loss: 0.1808 - Val Loss: 0.1754 - Val AUROC: 0.8151\n",
      "Epoch 3/25 - Gamma: 1.0 - Train Loss: 0.1764 - Val Loss: 0.1744 - Val AUROC: 0.8191\n",
      "Epoch 4/25 - Gamma: 1.0 - Train Loss: 0.1729 - Val Loss: 0.1746 - Val AUROC: 0.8198\n",
      "Epoch 5/25 - Gamma: 1.0 - Train Loss: 0.1700 - Val Loss: 0.1740 - Val AUROC: 0.8221\n",
      "Epoch 6/25 - Gamma: 1.0 - Train Loss: 0.1675 - Val Loss: 0.1730 - Val AUROC: 0.8239\n",
      "Epoch 7/25 - Gamma: 1.0 - Train Loss: 0.1647 - Val Loss: 0.1737 - Val AUROC: 0.8193\n",
      "Epoch 8/25 - Gamma: 1.0 - Train Loss: 0.1621 - Val Loss: 0.1743 - Val AUROC: 0.8212\n",
      "Training maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k with gamma=1.0...\n",
      "Epoch 1/25 - Gamma: 1.0 - Train Loss: 0.1902 - Val Loss: 0.1813 - Val AUROC: 0.8004\n",
      "Epoch 2/25 - Gamma: 1.0 - Train Loss: 0.1787 - Val Loss: 0.1744 - Val AUROC: 0.8173\n",
      "Epoch 3/25 - Gamma: 1.0 - Train Loss: 0.1743 - Val Loss: 0.1795 - Val AUROC: 0.8197\n",
      "Epoch 4/25 - Gamma: 1.0 - Train Loss: 0.1702 - Val Loss: 0.1718 - Val AUROC: 0.8226\n",
      "Epoch 5/25 - Gamma: 1.0 - Train Loss: 0.1665 - Val Loss: 0.1728 - Val AUROC: 0.8268\n",
      "Epoch 6/25 - Gamma: 1.0 - Train Loss: 0.1630 - Val Loss: 0.1717 - Val AUROC: 0.8306\n",
      "Epoch 7/25 - Gamma: 1.0 - Train Loss: 0.1589 - Val Loss: 0.1720 - Val AUROC: 0.8293\n",
      "Epoch 8/25 - Gamma: 1.0 - Train Loss: 0.1541 - Val Loss: 0.1740 - Val AUROC: 0.8307\n",
      "Epoch 9/25 - Gamma: 1.0 - Train Loss: 0.1485 - Val Loss: 0.1774 - Val AUROC: 0.8222\n",
      "Epoch 10/25 - Gamma: 1.0 - Train Loss: 0.1419 - Val Loss: 0.1844 - Val AUROC: 0.8111\n",
      "Training swin_large_patch4_window7_224 with gamma=1.0...\n",
      "Epoch 1/25 - Gamma: 1.0 - Train Loss: 0.1921 - Val Loss: 0.1796 - Val AUROC: 0.7932\n",
      "Epoch 2/25 - Gamma: 1.0 - Train Loss: 0.1805 - Val Loss: 0.1795 - Val AUROC: 0.7993\n",
      "Epoch 3/25 - Gamma: 1.0 - Train Loss: 0.1760 - Val Loss: 0.1735 - Val AUROC: 0.8213\n",
      "Epoch 4/25 - Gamma: 1.0 - Train Loss: 0.1728 - Val Loss: 0.1753 - Val AUROC: 0.8190\n",
      "Epoch 5/25 - Gamma: 1.0 - Train Loss: 0.1697 - Val Loss: 0.1747 - Val AUROC: 0.8233\n",
      "Epoch 6/25 - Gamma: 1.0 - Train Loss: 0.1661 - Val Loss: 0.1735 - Val AUROC: 0.8228\n",
      "Epoch 7/25 - Gamma: 1.0 - Train Loss: 0.1623 - Val Loss: 0.1777 - Val AUROC: 0.8235\n",
      "Epoch 8/25 - Gamma: 1.0 - Train Loss: 0.1582 - Val Loss: 0.1779 - Val AUROC: 0.8187\n",
      "Epoch 9/25 - Gamma: 1.0 - Train Loss: 0.1535 - Val Loss: 0.1784 - Val AUROC: 0.8177\n",
      "Training vgg19.tv_in1k with gamma=1.0...\n",
      "Epoch 1/25 - Gamma: 1.0 - Train Loss: 0.2015 - Val Loss: 0.1942 - Val AUROC: 0.7075\n",
      "Epoch 2/25 - Gamma: 1.0 - Train Loss: 0.1931 - Val Loss: 0.1889 - Val AUROC: 0.7466\n",
      "Epoch 3/25 - Gamma: 1.0 - Train Loss: 0.1886 - Val Loss: 0.1847 - Val AUROC: 0.7730\n",
      "Epoch 4/25 - Gamma: 1.0 - Train Loss: 0.1854 - Val Loss: 0.1817 - Val AUROC: 0.7817\n",
      "Epoch 5/25 - Gamma: 1.0 - Train Loss: 0.1827 - Val Loss: 0.1809 - Val AUROC: 0.7883\n",
      "Epoch 6/25 - Gamma: 1.0 - Train Loss: 0.1804 - Val Loss: 0.1788 - Val AUROC: 0.7946\n",
      "Epoch 7/25 - Gamma: 1.0 - Train Loss: 0.1786 - Val Loss: 0.1772 - Val AUROC: 0.7984\n",
      "Epoch 8/25 - Gamma: 1.0 - Train Loss: 0.1768 - Val Loss: 0.1800 - Val AUROC: 0.7924\n",
      "Epoch 9/25 - Gamma: 1.0 - Train Loss: 0.1752 - Val Loss: 0.1782 - Val AUROC: 0.8031\n",
      "Epoch 10/25 - Gamma: 1.0 - Train Loss: 0.1736 - Val Loss: 0.1785 - Val AUROC: 0.7957\n",
      "Epoch 11/25 - Gamma: 1.0 - Train Loss: 0.1724 - Val Loss: 0.1765 - Val AUROC: 0.8041\n",
      "Epoch 12/25 - Gamma: 1.0 - Train Loss: 0.1710 - Val Loss: 0.1768 - Val AUROC: 0.8043\n",
      "Epoch 13/25 - Gamma: 1.0 - Train Loss: 0.1693 - Val Loss: 0.1761 - Val AUROC: 0.8077\n",
      "Epoch 14/25 - Gamma: 1.0 - Train Loss: 0.1683 - Val Loss: 0.1763 - Val AUROC: 0.8048\n",
      "Epoch 15/25 - Gamma: 1.0 - Train Loss: 0.1665 - Val Loss: 0.1777 - Val AUROC: 0.8085\n",
      "Epoch 16/25 - Gamma: 1.0 - Train Loss: 0.1650 - Val Loss: 0.1821 - Val AUROC: 0.8039\n",
      "Epoch 17/25 - Gamma: 1.0 - Train Loss: 0.1635 - Val Loss: 0.1787 - Val AUROC: 0.8068\n",
      "Finished training for gamma=1.0, saved to '/student/csc490_project/shared/training_gamma/training_gamma_1.0'\n",
      "Starting training for gamma=1.2\n",
      "Training coatnet_2_rw_224.sw_in12k_ft_in1k with gamma=1.2...\n",
      "Epoch 1/25 - Gamma: 1.2 - Train Loss: 0.1998 - Val Loss: 0.1898 - Val AUROC: 0.7673\n",
      "Epoch 2/25 - Gamma: 1.2 - Train Loss: 0.1872 - Val Loss: 0.1828 - Val AUROC: 0.7901\n",
      "Epoch 3/25 - Gamma: 1.2 - Train Loss: 0.1823 - Val Loss: 0.1783 - Val AUROC: 0.8028\n",
      "Epoch 4/25 - Gamma: 1.2 - Train Loss: 0.1790 - Val Loss: 0.1754 - Val AUROC: 0.8151\n",
      "Epoch 5/25 - Gamma: 1.2 - Train Loss: 0.1765 - Val Loss: 0.1782 - Val AUROC: 0.8200\n",
      "Epoch 6/25 - Gamma: 1.2 - Train Loss: 0.1745 - Val Loss: 0.1743 - Val AUROC: 0.8241\n",
      "Epoch 7/25 - Gamma: 1.2 - Train Loss: 0.1726 - Val Loss: 0.1754 - Val AUROC: 0.8232\n",
      "Epoch 8/25 - Gamma: 1.2 - Train Loss: 0.1710 - Val Loss: 0.1741 - Val AUROC: 0.8242\n",
      "Epoch 9/25 - Gamma: 1.2 - Train Loss: 0.1695 - Val Loss: 0.1740 - Val AUROC: 0.8248\n",
      "Epoch 10/25 - Gamma: 1.2 - Train Loss: 0.1679 - Val Loss: 0.1728 - Val AUROC: 0.8348\n",
      "Epoch 11/25 - Gamma: 1.2 - Train Loss: 0.1930 - Val Loss: 0.1881 - Val AUROC: 0.7557\n",
      "Epoch 12/25 - Gamma: 1.2 - Train Loss: 0.1833 - Val Loss: 0.1764 - Val AUROC: 0.8101\n",
      "Training convnext_large.fb_in22k with gamma=1.2...\n",
      "Epoch 1/25 - Gamma: 1.2 - Train Loss: 0.1853 - Val Loss: 0.1794 - Val AUROC: 0.8133\n",
      "Epoch 2/25 - Gamma: 1.2 - Train Loss: 0.1722 - Val Loss: 0.1717 - Val AUROC: 0.8321\n",
      "Epoch 3/25 - Gamma: 1.2 - Train Loss: 0.1643 - Val Loss: 0.1735 - Val AUROC: 0.8315\n",
      "Epoch 4/25 - Gamma: 1.2 - Train Loss: 0.1532 - Val Loss: 0.1750 - Val AUROC: 0.8247\n",
      "Training densenet121 with gamma=1.2...\n",
      "Epoch 1/25 - Gamma: 1.2 - Train Loss: 0.1934 - Val Loss: 0.1784 - Val AUROC: 0.8028\n",
      "Epoch 2/25 - Gamma: 1.2 - Train Loss: 0.1803 - Val Loss: 0.1758 - Val AUROC: 0.8164\n",
      "Epoch 3/25 - Gamma: 1.2 - Train Loss: 0.1758 - Val Loss: 0.1754 - Val AUROC: 0.8194\n",
      "Epoch 4/25 - Gamma: 1.2 - Train Loss: 0.1725 - Val Loss: 0.1760 - Val AUROC: 0.8242\n",
      "Epoch 5/25 - Gamma: 1.2 - Train Loss: 0.1698 - Val Loss: 0.1738 - Val AUROC: 0.8247\n",
      "Epoch 6/25 - Gamma: 1.2 - Train Loss: 0.1667 - Val Loss: 0.1759 - Val AUROC: 0.8244\n",
      "Epoch 7/25 - Gamma: 1.2 - Train Loss: 0.1641 - Val Loss: 0.1748 - Val AUROC: 0.8246\n",
      "Training maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k with gamma=1.2...\n",
      "Epoch 1/25 - Gamma: 1.2 - Train Loss: 0.1885 - Val Loss: 0.1773 - Val AUROC: 0.8072\n",
      "Epoch 2/25 - Gamma: 1.2 - Train Loss: 0.1774 - Val Loss: 0.1776 - Val AUROC: 0.8159\n",
      "Epoch 3/25 - Gamma: 1.2 - Train Loss: 0.1727 - Val Loss: 0.1741 - Val AUROC: 0.8272\n",
      "Epoch 4/25 - Gamma: 1.2 - Train Loss: 0.1687 - Val Loss: 0.1731 - Val AUROC: 0.8294\n",
      "Epoch 5/25 - Gamma: 1.2 - Train Loss: 0.1646 - Val Loss: 0.1722 - Val AUROC: 0.8344\n",
      "Epoch 6/25 - Gamma: 1.2 - Train Loss: 0.1603 - Val Loss: 0.1719 - Val AUROC: 0.8328\n",
      "Epoch 7/25 - Gamma: 1.2 - Train Loss: 0.1555 - Val Loss: 0.1753 - Val AUROC: 0.8288\n",
      "Training swin_large_patch4_window7_224 with gamma=1.2...\n",
      "Epoch 1/25 - Gamma: 1.2 - Train Loss: 0.1923 - Val Loss: 0.1825 - Val AUROC: 0.7958\n",
      "Epoch 2/25 - Gamma: 1.2 - Train Loss: 0.1815 - Val Loss: 0.1780 - Val AUROC: 0.8072\n",
      "Epoch 3/25 - Gamma: 1.2 - Train Loss: 0.1770 - Val Loss: 0.1790 - Val AUROC: 0.8150\n",
      "Epoch 4/25 - Gamma: 1.2 - Train Loss: 0.1736 - Val Loss: 0.1763 - Val AUROC: 0.8210\n",
      "Epoch 5/25 - Gamma: 1.2 - Train Loss: 0.1705 - Val Loss: 0.1753 - Val AUROC: 0.8160\n",
      "Epoch 6/25 - Gamma: 1.2 - Train Loss: 0.1675 - Val Loss: 0.1752 - Val AUROC: 0.8226\n",
      "Epoch 7/25 - Gamma: 1.2 - Train Loss: 0.1640 - Val Loss: 0.1766 - Val AUROC: 0.8232\n",
      "Epoch 8/25 - Gamma: 1.2 - Train Loss: 0.1602 - Val Loss: 0.1778 - Val AUROC: 0.8160\n",
      "Epoch 9/25 - Gamma: 1.2 - Train Loss: 0.1559 - Val Loss: 0.1808 - Val AUROC: 0.8231\n",
      "Training vgg19.tv_in1k with gamma=1.2...\n",
      "Epoch 1/25 - Gamma: 1.2 - Train Loss: 0.2010 - Val Loss: 0.1937 - Val AUROC: 0.7377\n",
      "Epoch 2/25 - Gamma: 1.2 - Train Loss: 0.1926 - Val Loss: 0.1870 - Val AUROC: 0.7638\n",
      "Epoch 3/25 - Gamma: 1.2 - Train Loss: 0.1881 - Val Loss: 0.1860 - Val AUROC: 0.7745\n",
      "Epoch 4/25 - Gamma: 1.2 - Train Loss: 0.1847 - Val Loss: 0.1817 - Val AUROC: 0.7883\n",
      "Epoch 5/25 - Gamma: 1.2 - Train Loss: 0.1819 - Val Loss: 0.1818 - Val AUROC: 0.7905\n",
      "Epoch 6/25 - Gamma: 1.2 - Train Loss: 0.1799 - Val Loss: 0.1791 - Val AUROC: 0.7975\n",
      "Epoch 7/25 - Gamma: 1.2 - Train Loss: 0.1782 - Val Loss: 0.1768 - Val AUROC: 0.8029\n",
      "Epoch 8/25 - Gamma: 1.2 - Train Loss: 0.1764 - Val Loss: 0.1767 - Val AUROC: 0.8076\n",
      "Epoch 9/25 - Gamma: 1.2 - Train Loss: 0.1747 - Val Loss: 0.1774 - Val AUROC: 0.8083\n",
      "Epoch 10/25 - Gamma: 1.2 - Train Loss: 0.1734 - Val Loss: 0.1777 - Val AUROC: 0.8041\n",
      "Epoch 11/25 - Gamma: 1.2 - Train Loss: 0.1721 - Val Loss: 0.1799 - Val AUROC: 0.8021\n",
      "Finished training for gamma=1.2, saved to '/student/csc490_project/shared/training_gamma/training_gamma_1.2'\n"
     ]
    }
   ],
   "source": [
    "# Chest X-ray Multi-Label Classification with Gamma Correction Variants\n",
    "# Key Features:\n",
    "# - Patient-level stratified split\n",
    "# - Gamma correction [0.6, 0.8, 1.0, 1.2]\n",
    "# - Data augmentation for training\n",
    "# - BCEWithLogitsLoss\n",
    "# - Early stopping, LR scheduler, AUROC evaluation\n",
    "# - Best model saving, per-class results, loss curve plotting\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import timm\n",
    "\n",
    "# Define class labels\n",
    "CLASSES = [\n",
    "    \"No Finding\", \"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\",\n",
    "    \"Mass\", \"Nodule\", \"Pneumonia\", \"Pneumothorax\", \"Consolidation\",\n",
    "    \"Edema\", \"Emphysema\", \"Fibrosis\", \"Pleural_Thickening\", \"Hernia\"\n",
    "]\n",
    "num_classes = len(CLASSES)\n",
    "\n",
    "# Load dataset and encode multilabel targets\n",
    "df = pd.read_csv(\"/student/csc490_project/shared/labels.csv\")\n",
    "df[\"label_list\"] = df[\"Finding Labels\"].apply(lambda x: x.split(\"|\"))\n",
    "mlb = MultiLabelBinarizer(classes=CLASSES)\n",
    "df[\"labels\"] = list(mlb.fit_transform(df[\"label_list\"]))\n",
    "\n",
    "# Patient-level stratified split to avoid data leakage\n",
    "unique_patients = df[\"Patient ID\"].unique()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(unique_patients)\n",
    "train_end = int(0.7 * len(unique_patients))\n",
    "val_end = int(0.8 * len(unique_patients))\n",
    "train_patients = unique_patients[:train_end]\n",
    "val_patients = unique_patients[train_end:val_end]\n",
    "test_patients = unique_patients[val_end:]\n",
    "\n",
    "train_df = df[df[\"Patient ID\"].isin(train_patients)].reset_index(drop=True)\n",
    "val_df = df[df[\"Patient ID\"].isin(val_patients)].reset_index(drop=True)\n",
    "test_df = df[df[\"Patient ID\"].isin(test_patients)].reset_index(drop=True)\n",
    "\n",
    "# Validation/test transform without augmentation\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def get_train_transform(gamma):\n",
    "    \"\"\"\n",
    "    Returns the training transform pipeline with gamma correction and augmentations.\n",
    "\n",
    "    Args:\n",
    "        gamma (float): Gamma correction value.\n",
    "\n",
    "    Returns:\n",
    "        torchvision.transforms.Compose: Transform pipeline\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Lambda(lambda img: F.adjust_gamma(img, gamma)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# Dataset class to load images and their multilabel targets\n",
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame with image paths and labels.\n",
    "            root_dir (str): Path to image directory.\n",
    "            transform (callable): Transformations to apply to images.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.df.iloc[idx][\"Image Index\"])\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(self.df.iloc[idx][\"labels\"], dtype=torch.float32)\n",
    "        return image, label\n",
    "\n",
    "def get_model(model_name, num_classes):\n",
    "    \"\"\"\n",
    "    Loads a pretrained model from timm and modifies its output layer.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): timm model identifier.\n",
    "        num_classes (int): Number of output classes.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: Model instance\n",
    "    \"\"\"\n",
    "    return timm.create_model(model_name, pretrained=True, num_classes=num_classes)\n",
    "\n",
    "def compute_auroc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes per-class and mean AUROC.\n",
    "\n",
    "    Args:\n",
    "        y_true (list): Ground truth binary labels.\n",
    "        y_pred (list): Predicted probabilities.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (mean_auroc, list of per-class AUROC)\n",
    "    \"\"\"\n",
    "    y_true = np.vstack(y_true)\n",
    "    y_pred = np.vstack(y_pred)\n",
    "    try:\n",
    "        per_class_auroc = roc_auc_score(y_true, y_pred, average=None)\n",
    "        return np.mean(per_class_auroc), per_class_auroc\n",
    "    except:\n",
    "        return 0.0, [0.0] * num_classes\n",
    "\n",
    "def evaluate(model, device, loader):\n",
    "    \"\"\"\n",
    "    Evaluates a model on a DataLoader using sigmoid and AUROC.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Model to evaluate.\n",
    "        device (torch.device): CUDA or CPU.\n",
    "        loader (DataLoader): DataLoader for evaluation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (mean_auroc, list of per-class AUROC)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = torch.sigmoid(model(imgs)).cpu().numpy()\n",
    "            all_preds.append(outputs)\n",
    "            all_labels.append(labels.numpy())\n",
    "    return compute_auroc(all_labels, all_preds)\n",
    "\n",
    "def train_one_model(model_name, gamma, num_epochs=25, early_stopping_patience=2):\n",
    "    \"\"\"\n",
    "    Trains a single model with early stopping and AUROC tracking.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): timm model name.\n",
    "        gamma (float): Gamma value for gamma correction.\n",
    "        num_epochs (int): Max training epochs.\n",
    "        early_stopping_patience (int): Early stopping patience.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (val_auroc, test_auroc, val_aurocs, test_aurocs, model_path, final_train_loss, train_losses, val_losses, val_aurocs_epoch)\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = get_model(model_name, num_classes).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    best_val_auroc = 0\n",
    "    epochs_since_improvement = 0\n",
    "    best_model_path = None\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_aurocs_epoch = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        epoch_loss /= len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        val_auroc, _ = evaluate(model, device, val_loader)\n",
    "        val_aurocs_epoch.append(val_auroc)\n",
    "\n",
    "        val_epoch_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_epoch_loss += loss.item()\n",
    "        val_epoch_loss /= len(val_loader)\n",
    "        val_losses.append(val_epoch_loss)\n",
    "\n",
    "        scheduler.step(val_auroc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Gamma: {gamma} - Train Loss: {epoch_loss:.4f} - Val Loss: {val_epoch_loss:.4f} - Val AUROC: {val_auroc:.4f}\")\n",
    "\n",
    "        if val_auroc > best_val_auroc:\n",
    "            best_val_auroc = val_auroc\n",
    "            epochs_since_improvement = 0\n",
    "            model_path = f\"{gamma_dir}/{model_name.replace('/', '_')}.pt\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "            if epochs_since_improvement >= early_stopping_patience:\n",
    "                break\n",
    "\n",
    "    val_auroc, val_aurocs = evaluate(model, device, val_loader)\n",
    "    test_auroc, test_aurocs = evaluate(model, device, test_loader)\n",
    "    return val_auroc, test_auroc, val_aurocs, test_aurocs, model_path, train_losses[-1], train_losses, val_losses, val_aurocs_epoch\n",
    "\n",
    "# Main training loop with gamma correction variants\n",
    "# Saves results, checkpoints, and plots per gamma value\n",
    "\n",
    "data_root = \"/student/csc490_project/shared/preprocessed_images/preprocessed_images\"\n",
    "model_names = [\n",
    "    'coatnet_2_rw_224.sw_in12k_ft_in1k',\n",
    "    'convnext_large.fb_in22k',\n",
    "    'densenet121',\n",
    "    'maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k',\n",
    "    'swin_large_patch4_window7_224',\n",
    "    'vgg19.tv_in1k'\n",
    "]\n",
    "\n",
    "gamma_values = [0.6, 0.8, 1.0, 1.2]\n",
    "\n",
    "for gamma in gamma_values:\n",
    "    print(f\"Starting training for gamma={gamma}\")\n",
    "    train_transform = get_train_transform(gamma)\n",
    "\n",
    "    # Dataloaders with gamma-specific train transform\n",
    "    train_loader = DataLoader(ChestXrayDataset(train_df, data_root, train_transform), batch_size=16, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(ChestXrayDataset(val_df, data_root, val_test_transform), batch_size=16, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(ChestXrayDataset(test_df, data_root, val_test_transform), batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "    gamma_dir = f\"/student/csc490_project/shared/training_gamma/training_gamma_{gamma}\"\n",
    "    os.makedirs(gamma_dir, exist_ok=True)\n",
    "    os.makedirs(f\"{gamma_dir}/results\", exist_ok=True)\n",
    "    os.makedirs(f\"{gamma_dir}/loss_plots\", exist_ok=True)\n",
    "\n",
    "    results = {}\n",
    "    for model_name in model_names:\n",
    "        print(f\"Training {model_name} with gamma={gamma}...\")\n",
    "        val_auroc, test_auroc, val_aurocs, test_aurocs, model_path, final_loss, train_loss_history, val_loss_history, val_aurocs_epoch = train_one_model(model_name, gamma)\n",
    "\n",
    "        # Save training results and metrics\n",
    "        model_results = {\n",
    "            \"val_auroc\": val_auroc,\n",
    "            \"val_aurocs_epoch\": val_aurocs_epoch,\n",
    "            \"test_auroc\": test_auroc,\n",
    "            \"model_path\": model_path,\n",
    "            \"final_train_loss\": final_loss,\n",
    "            \"train_loss_history\": train_loss_history,\n",
    "            \"val_loss_history\": val_loss_history\n",
    "        }\n",
    "        for i, cls in enumerate(CLASSES):\n",
    "            model_results[f\"val_{cls}\"] = val_aurocs[i]\n",
    "            model_results[f\"test_{cls}\"] = test_aurocs[i]\n",
    "        results[model_name] = model_results\n",
    "\n",
    "        pd.DataFrame([model_results]).to_csv(f\"{gamma_dir}/results/{model_name.replace('/', '_')}.csv\", index=False)\n",
    "\n",
    "    pd.DataFrame(results).T.to_csv(f\"{gamma_dir}/model_aurocs_per_class.csv\")\n",
    "\n",
    "    with open(f\"{gamma_dir}/all_loss_histories.json\", \"w\") as f:\n",
    "        json.dump({k: {\"train\": v[\"train_loss_history\"], \"val\": v[\"val_loss_history\"], \"val_auroc\": v[\"val_aurocs_epoch\"]} for k, v in results.items()}, f)\n",
    "\n",
    "    with open(f\"{gamma_dir}/all_loss_histories.json\", \"r\") as f:\n",
    "        loss_data = json.load(f)\n",
    "\n",
    "    for model_name, losses in loss_data.items():\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(losses[\"train\"], label=\"Train Loss\", linewidth=2)\n",
    "        plt.plot(losses[\"val\"], label=\"Val Loss\", linewidth=2)\n",
    "        plt.plot(losses[\"val_auroc\"], label=\"Val AUROC\", linewidth=2)\n",
    "        plt.title(f\"{model_name} - Gamma={gamma} Loss Curve\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{gamma_dir}/loss_plots/{model_name.replace('/', '_')}_loss_curve.png\")\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"Finished training for gamma={gamma}, saved to '{gamma_dir}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
