{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training coatnet_2_rw_224.sw_in12k_ft_in1k...\n",
      "Epoch 1/25 - Train Loss: 0.1997 - Val Loss: 0.1883 - Val AUROC: 0.7558\n",
      "Epoch 2/25 - Train Loss: 0.1872 - Val Loss: 0.1943 - Val AUROC: 0.7865\n",
      "Epoch 3/25 - Train Loss: 0.1821 - Val Loss: 0.1763 - Val AUROC: 0.8143\n",
      "Epoch 4/25 - Train Loss: 0.1788 - Val Loss: 0.1763 - Val AUROC: 0.8139\n",
      "Epoch 5/25 - Train Loss: 0.1768 - Val Loss: 0.1753 - Val AUROC: 0.8197\n",
      "Epoch 6/25 - Train Loss: 0.1791 - Val Loss: 0.1768 - Val AUROC: 0.8170\n",
      "Epoch 7/25 - Train Loss: 0.1735 - Val Loss: 0.1756 - Val AUROC: 0.8223\n",
      "Epoch 8/25 - Train Loss: 0.1725 - Val Loss: 0.1752 - Val AUROC: 0.8276\n",
      "Epoch 9/25 - Train Loss: 0.1709 - Val Loss: 0.1744 - Val AUROC: 0.8286\n",
      "Epoch 10/25 - Train Loss: 0.1693 - Val Loss: 0.1725 - Val AUROC: 0.8316\n",
      "Epoch 11/25 - Train Loss: 0.1676 - Val Loss: 0.1719 - Val AUROC: 0.8318\n",
      "Epoch 12/25 - Train Loss: 0.1661 - Val Loss: 0.1706 - Val AUROC: 0.8351\n",
      "Epoch 13/25 - Train Loss: 0.1643 - Val Loss: 0.1710 - Val AUROC: 0.8323\n",
      "Epoch 14/25 - Train Loss: 0.1637 - Val Loss: 0.1716 - Val AUROC: 0.8297\n",
      "Training convnext_large.fb_in22k...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f6315f8b774875893c86240e07d6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/919M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Train Loss: 0.1855 - Val Loss: 0.1761 - Val AUROC: 0.8068\n",
      "Epoch 2/25 - Train Loss: 0.1727 - Val Loss: 0.1722 - Val AUROC: 0.8269\n",
      "Epoch 3/25 - Train Loss: 0.1648 - Val Loss: 0.1726 - Val AUROC: 0.8306\n",
      "Epoch 4/25 - Train Loss: 0.1544 - Val Loss: 0.1756 - Val AUROC: 0.8276\n",
      "Epoch 5/25 - Train Loss: 0.1382 - Val Loss: 0.1868 - Val AUROC: 0.8162\n",
      "Training densenet121...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dae378f4fb046da86ed506c67c78718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/32.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Train Loss: 0.1935 - Val Loss: 0.1785 - Val AUROC: 0.8025\n",
      "Epoch 2/25 - Train Loss: 0.1801 - Val Loss: 0.1758 - Val AUROC: 0.8147\n",
      "Epoch 3/25 - Train Loss: 0.1760 - Val Loss: 0.1739 - Val AUROC: 0.8205\n",
      "Epoch 4/25 - Train Loss: 0.1727 - Val Loss: 0.1762 - Val AUROC: 0.8212\n",
      "Epoch 5/25 - Train Loss: 0.1697 - Val Loss: 0.1739 - Val AUROC: 0.8246\n",
      "Epoch 6/25 - Train Loss: 0.1672 - Val Loss: 0.1729 - Val AUROC: 0.8255\n",
      "Epoch 7/25 - Train Loss: 0.1643 - Val Loss: 0.1756 - Val AUROC: 0.8246\n",
      "Epoch 8/25 - Train Loss: 0.1615 - Val Loss: 0.1773 - Val AUROC: 0.8230\n",
      "Training maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898a241bf1184fd2828103fc2a0488eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/465M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Train Loss: 0.1903 - Val Loss: 0.1779 - Val AUROC: 0.8085\n",
      "Epoch 2/25 - Train Loss: 0.1787 - Val Loss: 0.1802 - Val AUROC: 0.8060\n",
      "Epoch 3/25 - Train Loss: 0.1738 - Val Loss: 0.1759 - Val AUROC: 0.8152\n",
      "Epoch 4/25 - Train Loss: 0.1700 - Val Loss: 0.1724 - Val AUROC: 0.8263\n",
      "Epoch 5/25 - Train Loss: 0.1662 - Val Loss: 0.1712 - Val AUROC: 0.8330\n",
      "Epoch 6/25 - Train Loss: 0.1625 - Val Loss: 0.1738 - Val AUROC: 0.8287\n",
      "Epoch 7/25 - Train Loss: 0.1585 - Val Loss: 0.1756 - Val AUROC: 0.8262\n",
      "Training swin_large_patch4_window7_224...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069ef12fc3bd48ca8aa54d8825a21035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/788M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Train Loss: 0.1910 - Val Loss: 0.1783 - Val AUROC: 0.8016\n",
      "Epoch 2/25 - Train Loss: 0.1800 - Val Loss: 0.1766 - Val AUROC: 0.8125\n",
      "Epoch 3/25 - Train Loss: 0.1755 - Val Loss: 0.1755 - Val AUROC: 0.8177\n",
      "Epoch 4/25 - Train Loss: 0.1719 - Val Loss: 0.1734 - Val AUROC: 0.8248\n",
      "Epoch 5/25 - Train Loss: 0.1689 - Val Loss: 0.1726 - Val AUROC: 0.8242\n",
      "Epoch 6/25 - Train Loss: 0.1655 - Val Loss: 0.1746 - Val AUROC: 0.8244\n",
      "Training vgg19.tv_in1k...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab84dce1134049eea7e2a502780e8500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/575M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Train Loss: 0.2006 - Val Loss: 0.1928 - Val AUROC: 0.7319\n",
      "Epoch 2/25 - Train Loss: 0.1921 - Val Loss: 0.1855 - Val AUROC: 0.7698\n",
      "Epoch 3/25 - Train Loss: 0.1869 - Val Loss: 0.1858 - Val AUROC: 0.7650\n",
      "Epoch 4/25 - Train Loss: 0.1835 - Val Loss: 0.1802 - Val AUROC: 0.7929\n",
      "Epoch 5/25 - Train Loss: 0.1810 - Val Loss: 0.1805 - Val AUROC: 0.7923\n",
      "Epoch 6/25 - Train Loss: 0.1789 - Val Loss: 0.1791 - Val AUROC: 0.7970\n",
      "Epoch 7/25 - Train Loss: 0.1771 - Val Loss: 0.1774 - Val AUROC: 0.7984\n",
      "Epoch 8/25 - Train Loss: 0.1757 - Val Loss: 0.1793 - Val AUROC: 0.7977\n",
      "Epoch 9/25 - Train Loss: 0.1741 - Val Loss: 0.1786 - Val AUROC: 0.8058\n",
      "Epoch 10/25 - Train Loss: 0.1725 - Val Loss: 0.1788 - Val AUROC: 0.8068\n",
      "Epoch 11/25 - Train Loss: 0.1709 - Val Loss: 0.1777 - Val AUROC: 0.8113\n",
      "Epoch 12/25 - Train Loss: 0.1693 - Val Loss: 0.1762 - Val AUROC: 0.8114\n",
      "Epoch 13/25 - Train Loss: 0.1677 - Val Loss: 0.1757 - Val AUROC: 0.8149\n",
      "Epoch 14/25 - Train Loss: 0.1663 - Val Loss: 0.1776 - Val AUROC: 0.8146\n",
      "Epoch 15/25 - Train Loss: 0.1644 - Val Loss: 0.1792 - Val AUROC: 0.8060\n",
      "Saved loss curves, model weights, per-model and combined CSVs, and performance metrics to '/student/csc490_project/shared/training/'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Training Pipeline for Chest X-ray Multi-Label Classification\n",
    "# Features:\n",
    "# - Patient-level stratified train/val/test split\n",
    "# - Data augmentation for training set\n",
    "# - Custom PyTorch Dataset class for image-label pairing\n",
    "# - Pretrained model loading and fine-tuning using timm\n",
    "# - BCEWithLogitsLoss for multilabel classification\n",
    "# - Learning rate scheduler and early stopping\n",
    "# - Per-epoch tracking of training and validation loss\n",
    "# - Computation of overall and per-class AUROC\n",
    "# - Best model checkpointing based on validation AUROC\n",
    "# - Logging all results and loss histories to disk\n",
    "# - Saving loss curve plots per model\n",
    "# - Train/Val AUROC\n",
    "# - Train/Val loss tracking\n",
    "# - Early stopping\n",
    "# - Scheduler\n",
    "# - Best model saving\n",
    "# - Individual loss curve plots per model\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import timm\n",
    "\n",
    "# 1. Define class labels for 15 disease categories\n",
    "CLASSES = [\n",
    "    \"No Finding\", \"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\",\n",
    "    \"Mass\", \"Nodule\", \"Pneumonia\", \"Pneumothorax\", \"Consolidation\",\n",
    "    \"Edema\", \"Emphysema\", \"Fibrosis\", \"Pleural_Thickening\", \"Hernia\"\n",
    "]\n",
    "num_classes = len(CLASSES)\n",
    "\n",
    "# 2. Load dataset and apply patient-level stratified split\n",
    "df = pd.read_csv(\"/student/csc490_project/shared/labels.csv\")\n",
    "df[\"label_list\"] = df[\"Finding Labels\"].apply(lambda x: x.split(\"|\"))\n",
    "mlb = MultiLabelBinarizer(classes=CLASSES)\n",
    "df[\"labels\"] = list(mlb.fit_transform(df[\"label_list\"]))\n",
    "\n",
    "# Ensure no patient leakage between splits\n",
    "unique_patients = df[\"Patient ID\"].unique()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(unique_patients)\n",
    "train_end = int(0.7 * len(unique_patients))\n",
    "val_end = int(0.8 * len(unique_patients))\n",
    "train_patients = unique_patients[:train_end]\n",
    "val_patients = unique_patients[train_end:val_end]\n",
    "test_patients = unique_patients[val_end:]\n",
    "\n",
    "assert set(train_patients).isdisjoint(val_patients)\n",
    "assert set(train_patients).isdisjoint(test_patients)\n",
    "assert set(val_patients).isdisjoint(test_patients)\n",
    "\n",
    "# Subset dataframes by patient groups\n",
    "train_df = df[df[\"Patient ID\"].isin(train_patients)].reset_index(drop=True)\n",
    "val_df = df[df[\"Patient ID\"].isin(val_patients)].reset_index(drop=True)\n",
    "test_df = df[df[\"Patient ID\"].isin(test_patients)].reset_index(drop=True)\n",
    "\n",
    "# 3. Define image transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 4. Dataset class for loading X-ray images and labels\n",
    "class ChestXrayDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for Chest X-ray multi-label classification.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe containing image paths and labels.\n",
    "        root_dir (str): Path to the directory containing images.\n",
    "        transform (callable, optional): Transformations to apply to images.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.df.iloc[idx][\"Image Index\"])\n",
    "        image = Image.open(img_path).convert(\"L\")  # Convert to grayscale\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(self.df.iloc[idx][\"labels\"], dtype=torch.float32)\n",
    "        return image, label\n",
    "\n",
    "# 5. Create dataloaders for train, validation, and test\n",
    "data_root = \"/student/csc490_project/shared/preprocessed_images/preprocessed_images\"\n",
    "train_loader = DataLoader(ChestXrayDataset(train_df, data_root, train_transform), batch_size=16, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(ChestXrayDataset(val_df, data_root, val_test_transform), batch_size=16, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(ChestXrayDataset(test_df, data_root, val_test_transform), batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "# 6. Helper to load pretrained model\n",
    "\n",
    "def get_model(model_name, num_classes):\n",
    "    \"\"\"\n",
    "    Load a pretrained model from timm with the specified output size.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): timm model identifier.\n",
    "        num_classes (int): Number of output classes.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: Model with modified classification head.\n",
    "    \"\"\"\n",
    "    return timm.create_model(model_name, pretrained=True, num_classes=num_classes)\n",
    "\n",
    "# 7. AUROC computation and evaluation routines\n",
    "\n",
    "def compute_auroc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute mean and per-class AUROC.\n",
    "\n",
    "    Args:\n",
    "        y_true (list): Ground truth binary labels.\n",
    "        y_pred (list): Predicted probabilities.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Mean AUROC, per-class AUROCs\n",
    "    \"\"\"\n",
    "    y_true = np.vstack(y_true)\n",
    "    y_pred = np.vstack(y_pred)\n",
    "    try:\n",
    "        per_class_auroc = roc_auc_score(y_true, y_pred, average=None)\n",
    "        return np.mean(per_class_auroc), per_class_auroc\n",
    "    except:\n",
    "        return 0.0, [0.0] * num_classes\n",
    "\n",
    "def evaluate(model, device, loader):\n",
    "    \"\"\"\n",
    "    Evaluate model using AUROC on given DataLoader.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Trained model.\n",
    "        device (torch.device): Torch device.\n",
    "        loader (DataLoader): Dataset loader.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Mean AUROC, per-class AUROCs\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = torch.sigmoid(model(imgs)).cpu().numpy()\n",
    "            all_preds.append(outputs)\n",
    "            all_labels.append(labels.numpy())\n",
    "    return compute_auroc(all_labels, all_preds)\n",
    "\n",
    "# 8. Training loop with early stopping and checkpointing\n",
    "\n",
    "def train_one_model(model_name, num_epochs=25, early_stopping_patience=2):\n",
    "    \"\"\"\n",
    "    Train a single model with early stopping and save best checkpoint.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of model to train.\n",
    "        num_epochs (int): Number of training epochs.\n",
    "        early_stopping_patience (int): Patience for early stopping.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (val_auroc, test_auroc, val_aurocs, test_aurocs, model_path, final_train_loss, train_losses, val_losses, val_aurocs_epoch)\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = get_model(model_name, num_classes).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    best_val_auroc = 0\n",
    "    epochs_since_improvement = 0\n",
    "    best_model_path = None\n",
    "    train_losses = []\n",
    "    val_aurocs_epoch = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        epoch_loss /= num_batches\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        val_auroc, _ = evaluate(model, device, val_loader)\n",
    "        val_aurocs_epoch.append(val_auroc)\n",
    "\n",
    "        # Validation loss\n",
    "        val_epoch_loss = 0\n",
    "        num_val_batches = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_epoch_loss += loss.item()\n",
    "                num_val_batches += 1\n",
    "        val_epoch_loss /= num_val_batches\n",
    "        val_losses.append(val_epoch_loss)\n",
    "\n",
    "        scheduler.step(val_auroc)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_loss:.4f} - Val Loss: {val_epoch_loss:.4f} - Val AUROC: {val_auroc:.4f}\")\n",
    "\n",
    "        if val_auroc > best_val_auroc:\n",
    "            best_val_auroc = val_auroc\n",
    "            epochs_since_improvement = 0\n",
    "            os.makedirs(\"/student/csc490_project/shared/training\", exist_ok=True)\n",
    "            os.makedirs(\"/student/csc490_project/shared/training/results\", exist_ok=True)\n",
    "            best_model_path = f\"/student/csc490_project/shared/training/{model_name.replace('/', '_')}.pt\"\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "            if epochs_since_improvement >= early_stopping_patience:\n",
    "                break\n",
    "\n",
    "    val_auroc, val_aurocs = evaluate(model, device, val_loader)\n",
    "    test_auroc, test_aurocs = evaluate(model, device, test_loader)\n",
    "    return val_auroc, test_auroc, val_aurocs, test_aurocs, best_model_path, train_losses[-1], train_losses, val_losses, val_aurocs_epoch\n",
    "\n",
    "# 9. Train each model and log results\n",
    "model_names = [\n",
    "    'coatnet_2_rw_224.sw_in12k_ft_in1k',\n",
    "    'convnext_large.fb_in22k',\n",
    "    'densenet121',\n",
    "    'maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k',\n",
    "    'swin_large_patch4_window7_224',\n",
    "    'vgg19.tv_in1k'\n",
    "]\n",
    "\n",
    "results = {}\n",
    "for model_name in model_names:\n",
    "    print(f\"Training {model_name}...\")\n",
    "    val_auroc, test_auroc, val_aurocs, test_aurocs, model_path, final_loss, train_loss_history, val_loss_history, val_aurocs_epoch = train_one_model(model_name)\n",
    "    model_results = {\n",
    "        \"val_auroc\": val_auroc,\n",
    "        \"val_aurocs_epoch\": val_aurocs_epoch,\n",
    "        \"test_auroc\": test_auroc,\n",
    "        \"model_path\": model_path,\n",
    "        \"final_train_loss\": final_loss,\n",
    "        \"train_loss_history\": train_loss_history,\n",
    "        \"val_loss_history\": val_loss_history\n",
    "    }\n",
    "    for i, cls in enumerate(CLASSES):\n",
    "        model_results[f\"val_{cls}\"] = val_aurocs[i]\n",
    "        model_results[f\"test_{cls}\"] = test_aurocs[i]\n",
    "    results[model_name] = model_results\n",
    "\n",
    "    pd.DataFrame([model_results]).to_csv(f\"/student/csc490_project/shared/training/results/{model_name.replace('/', '_')}.csv\", index=False)\n",
    "\n",
    "# Save combined results and plots\n",
    "pd.DataFrame(results).T.to_csv(\"/student/csc490_project/shared/training/model_aurocs_per_class.csv\")\n",
    "\n",
    "with open(\"/student/csc490_project/shared/training/all_loss_histories.json\", \"w\") as f:\n",
    "    json.dump({k: {\"train\": v[\"train_loss_history\"], \"val\": v[\"val_loss_history\"], \"val_auroc\": v[\"val_aurocs_epoch\"]} for k, v in results.items()}, f)\n",
    "\n",
    "os.makedirs(\"/student/csc490_project/shared/training/loss_plots\", exist_ok=True)\n",
    "with open(\"/student/csc490_project/shared/training/all_loss_histories.json\", \"r\") as f:\n",
    "    loss_data = json.load(f)\n",
    "\n",
    "# Plot loss and AUROC curves for each model\n",
    "for model_name, losses in loss_data.items():\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(losses[\"train\"], label=\"Train Loss\", linewidth=2)\n",
    "    plt.plot(losses[\"val\"], label=\"Val Loss\", linewidth=2)\n",
    "    plt.plot(losses[\"val_auroc\"], label=\"Val AUROC\", linewidth=2)\n",
    "    plt.title(f\"{model_name} - Loss Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/student/csc490_project/shared/training/loss_plots/{model_name.replace('/', '_')}_loss_curve.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"Saved loss curves, model weights, per-model and combined CSVs, and performance metrics to '/student/csc490_project/shared/training/'\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
